{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lxml\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script summary\n",
    "- Import many xml files that were generated by the Send to Roadnet process in D365\n",
    "- Perform processing on the XML files, and import them into a Pandas dataframe containing outbound order lines from D365\n",
    "- Convert this into a dataframe that emulates the data that Roadnet would have returned - apply spec for every field in the file\n",
    "- Import a list of SessionIDs, one for each user (or virtual user) that will be importing and posting an inbound file from Roadnet\n",
    "- Split the inbound file (from Roadnet) into one file per SessionID\n",
    "- Export as CSV (take note lines must end with CR-NL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up temporary folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set filenames\n",
    "consolidated_roadnet_out_file = 'data/roadnet/xml_consolidated/consolidated_roadnet_out.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove(consolidated_roadnet_out_file)\n",
    "except:\n",
    "    pass\n",
    "    #print(consolidated_roadnet_out_file + ' not in folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the xml_prep folder\n",
    "path = \"data/roadnet/xml_prep/\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "for i in range(0,len(dir_list)):\n",
    "    xml_file = path+dir_list[i]\n",
    "    os.remove(xml_file)\n",
    "\n",
    "# Clean up the xml_consolidated folder\n",
    "path = \"data/roadnet/xml_consolidated/\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "for i in range(0,len(dir_list)):\n",
    "    xml_file = path+dir_list[i]\n",
    "    os.remove(xml_file)    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert D365 XML outbound files from a single line (with no newlines) to multiple lines by inserting a newline after evert '>' character\n",
    "- Store the resulting files in the /xml_prep/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1 XML files in  data/roadnet/xml_outbound/\n"
     ]
    }
   ],
   "source": [
    "# Get the list of all files and directories\n",
    "path = \"data/roadnet/xml_outbound/\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "print(\"Loading \" + str(len(dir_list)) + \" XML files in \", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_multiple_lines(fname, fnum):\n",
    "\n",
    "    with open(fname, 'r') as fr:\n",
    "        # reading line by line\n",
    "        lines = fr.readlines()\n",
    "        last_line = len(lines)\n",
    "        #print(last_line)\n",
    "\n",
    "    for line in lines:\n",
    "        replaced_line = re.sub(\">\", \">\\u000A\", line)\n",
    "\n",
    "    outfile = 'data/roadnet/xml_prep/f'+str(fnum)+'.xml'\n",
    "\n",
    "    with open(outfile, 'w') as fw:\n",
    "        fw.write(replaced_line)    \n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert xml from D365 by adding newlines\n",
    "\n",
    "for i in range(0,len(dir_list)):\n",
    "    xml_file = path+dir_list[i]\n",
    "    #print(xml_file)\n",
    "    xml_to_multiple_lines(xml_file,i)\n",
    "\n",
    "number_of_xml = len(dir_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidate the processed XML outbound files into a single, consolidated xml file\n",
    "- Remove all lines that are not transaction line items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of all files and directories\n",
    "path = \"data/roadnet/xml_prep/\"\n",
    "prep_dir_list = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_roadnet_files2(fname, fnum, outfile):\n",
    "\n",
    "    try:    \n",
    "        with open(fname, 'r') as fr:\n",
    "            # reading line by line\n",
    "            lines = fr.readlines()\n",
    "\n",
    "            last_line = len(lines)\n",
    "\n",
    "            # opening in writing mode\n",
    "            with open(outfile, 'a') as fw:\n",
    "                for line in lines:      \n",
    "                    substr1 = 'CCBROADNETWORKBENCHSESSIONTABLEENTITY'       \n",
    "                    x1 = re.search(substr1, line)\n",
    "                    substr2 = 'Document>'       \n",
    "                    x2 = re.search(substr2, line)\n",
    "                    substr3 = 'xml version='       \n",
    "                    x3 = re.search(substr3, line)\n",
    "                    #print(x)\n",
    "                    if x1 == None and x2 == None and x3 == None:\n",
    "                        fw.write(line)\n",
    "        #print(fname+\" lines deleted\")\n",
    "\n",
    "    except:\n",
    "        print(\"Error importing \"+fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(prep_dir_list)):\n",
    "    xml_file = path+prep_dir_list[i]\n",
    "    #print(i)\n",
    "    #print(xml_file)\n",
    "    import_roadnet_files2(xml_file,i, consolidated_roadnet_out_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split up the consolidated xml file into 10,000 lines or fewer, else they cannot be imported into a Pandas dataframe\n",
    "- Store these files in the same folder as the consolidated xml, and delete the consolidated xml after the split\n",
    "- Add the lines to turn this into a valid XML format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = consolidated_roadnet_out_file\n",
    "outfile = fname\n",
    "\n",
    "try:    \n",
    "    with open(fname, 'r') as fr:\n",
    "        # reading line by line\n",
    "        lines = fr.readlines()\n",
    "\n",
    "        last_line = len(lines)\n",
    "\n",
    "        line_counter = 1\n",
    "\n",
    "        # opening in writing mode\n",
    "        last_x = 0\n",
    "        for i in range(0,len(lines)):\n",
    "            line = lines[i]\n",
    "            if i == last_line:\n",
    "                print(line)\n",
    "            x = int(i/10000)\n",
    "            with open(outfile[:-4]+str(x)+'.xml', 'a') as fw:        \n",
    "                if i == 0:\n",
    "                    fw.write('<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n')\n",
    "                    fw.write('<Document>\\n')\n",
    "                if x > last_x:\n",
    "                    last_x = x\n",
    "                    fw.write('<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n')\n",
    "                    fw.write('<Document>\\n')\n",
    "                fw.write(line)\n",
    "                if int((i+1)/10000) > x:\n",
    "                    fw.write('</Document>')\n",
    "                if i == len(lines) - 1:\n",
    "                    fw.write('</Document>')\n",
    "    os.remove(consolidated_roadnet_out_file)\n",
    "                \n",
    "except:\n",
    "    print(\"Error importing \"+fname)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the transformed XML files into a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of all files and directories\n",
    "path = \"data/roadnet/xml_consolidated/\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "#print(\"Files and directories in '\", path, \"' :\")\n",
    "\n",
    "# prints all files\n",
    "#print(dir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the first file into a dataframe\n",
    "rdnet_out = pd.read_xml(path+dir_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the rest of the files, and append to the dataframe\n",
    "for i in range(1,len(dir_list)):\n",
    "    xml_file = path+dir_list[i]\n",
    "    print(str(i)+xml_file)\n",
    "    temp = pd.read_xml(path+dir_list[i])\n",
    "    rdnet_out = pd.concat([rdnet_out, temp], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Roadnet inbound file by copying selected columns as-is from the outbound data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in = rdnet_out[['QUANTITY','LOCATIONID','INVENTTRANSID','ITEMID','ORDERID','WAREHOUSEID','PRODUCTNAME','ROADNETROUTE','ORDERACCOUNT','ORDERACCOUNTNAME','WEIGHT']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in.rename(columns={'QUANTITY':'CASEQTY','LOCATIONID':'DESTINATIONLOCATIONID','ORDERID':'ORDERNUMBER','WAREHOUSEID':'ORIGINLOCATIONID','ORDERACCOUNT':'STOPLOCATIONID','ORDERACCOUNTNAME':'STOPLOCATIONNAME'}, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the rest of the fields as per the Roadnet inbound file spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rdnet_in['DYNAMICSRETRIEVALSESSIONID'] = 'ZA1-000000661'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = str(datetime.now())\n",
    "today = today.replace(':','h')\n",
    "today = today.replace('-','')\n",
    "today = today.replace(' ','-')\n",
    "today = today[0:14] + '-'\n",
    "#print(\"Today date is: \", today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in['ROADNETROUTEINTERNALROUTEID'] = today + rdnet_in['STOPLOCATIONID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_customers = len(rdnet_in['STOPLOCATIONID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in['APPTID'] = ''\n",
    "rdnet_in['DESCRIPTION'] = 'BLOEM_PLAN'\n",
    "rdnet_in['ERROR'] = ''\n",
    "rdnet_in['FIRSTDRIVER'] = '825196'\n",
    "rdnet_in['FIRSTTRAILER'] = 'ST29PTAIL'\n",
    "rdnet_in['LASTSTOPISDESTINATION'] = 'No'\n",
    "rdnet_in['LOADID'] = ''\n",
    "rdnet_in['LOADTEMPLATEID'] = ''\n",
    "rdnet_in['ORDERTYPE'] = 'rotOrder'\n",
    "rdnet_in['ORIGINDESTINATION'] = 'Yes'\n",
    "rdnet_in['PALLETQTY'] = '0'\n",
    "rdnet_in['REFERENCECATEGORY'] = 'Sales'\n",
    "rdnet_in['REFERENCEDOCUMENT'] = 'SalesOrder'\n",
    "rdnet_in['ROADNETINTERNALSESSIONID'] = '35411'\n",
    "rdnet_in['ROADNETREGIONID'] = 'ZA1'\n",
    "rdnet_in['ROUTECODE'] = ''\n",
    "rdnet_in['SECONDDRIVER'] = ''\n",
    "rdnet_in['SECONDTRAILER'] = ''\n",
    "rdnet_in['SEQUENCEDISTANCE'] = '.000000'\n",
    "rdnet_in['SEQUENCENUMBER'] = '1'\n",
    "rdnet_in['SEQUENCETRAVELTIME'] = '0'\n",
    "rdnet_in['SHIPPINGCARRIER'] = '0'\n",
    "rdnet_in['STATUS'] = 'Error'\n",
    "rdnet_in['STOPTYPE'] = 'stpStop'\n",
    "rdnet_in['TOTALDISTANCE'] = '.000000'\n",
    "rdnet_in['TOTALROUTEDISTANCE'] = '.000000'\n",
    "rdnet_in['TRUCKANDTRAILERASSIGNED'] = 'No'\n",
    "rdnet_in['UNITID'] = ''\n",
    "rdnet_in['VEHICLEID'] = 'TT4X2TAIL'\n",
    "rdnet_in['STOPSERVICETIME'] = '720'\n",
    "rdnet_in['TOTALSERVICETIME'] = '720'\n",
    "rdnet_in['TOTALTRAVELTIME'] = '0'\n",
    "rdnet_in['LINEREFID'] = rdnet_in['INVENTTRANSID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_txt = input('Enter the dispatch date in the format yyyy-mm-dd: ')\n",
    "date_dt = pd.to_datetime(date_txt)\n",
    "#date_dt = pd.to_datetime('today')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in['ROUTECOMPLETETIME'] = date_dt\n",
    "rdnet_in['ROUTECOMPLETETIME'] = rdnet_in['ROUTECOMPLETETIME'].dt.normalize() + pd.Timedelta(days=0) + pd.Timedelta(hours=13) + pd.Timedelta(minutes=19)\n",
    "\n",
    "rdnet_in['ROUTESTARTTIME'] = date_dt\n",
    "rdnet_in['ROUTESTARTTIME'] = rdnet_in['ROUTESTARTTIME'].dt.normalize() + pd.Timedelta(days=0) + pd.Timedelta(hours=4) + pd.Timedelta(minutes=0)\n",
    "\n",
    "rdnet_in['SCHEDULEDARRIVALDATETIME'] = date_dt\n",
    "rdnet_in['SCHEDULEDARRIVALDATETIME'] = rdnet_in['SCHEDULEDARRIVALDATETIME'].dt.normalize() + pd.Timedelta(days=0) + pd.Timedelta(hours=12) + pd.Timedelta(minutes=59)\n",
    "\n",
    "rdnet_in['SCHEDULEDDELIVERYDATETIME'] = date_dt\n",
    "rdnet_in['SCHEDULEDDELIVERYDATETIME'] = rdnet_in['SCHEDULEDDELIVERYDATETIME'].dt.normalize() + pd.Timedelta(days=0)\n",
    "\n",
    "rdnet_in['SCHEDULEDSHIPDATETIME'] = date_dt\n",
    "rdnet_in['SCHEDULEDSHIPDATETIME'] = rdnet_in['SCHEDULEDSHIPDATETIME'].dt.normalize() + pd.Timedelta(days=0) + pd.Timedelta(hours=4) + pd.Timedelta(minutes=10)\n",
    "\n",
    "rdnet_in['STOPARRIVALTIME'] = date_dt\n",
    "rdnet_in['STOPARRIVALTIME'] = rdnet_in['STOPARRIVALTIME'].dt.normalize() + pd.Timedelta(days=0) + pd.Timedelta(hours=8) + pd.Timedelta(minutes=28)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get customer master in order to get the postal code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the customer master to obtain the zipcode\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading the customer master to obtain the zipcode\")\n",
    "customers=pd.read_csv('data/customer_master.csv',low_memory=False)\n",
    "customers_short = customers[['ADDRESSZIPCODE','CUSTOMERACCOUNT','ORGANIZATIONNAME']].copy()\n",
    "customers_short['ADDRESSZIPCODE'] = customers_short['ADDRESSZIPCODE'].fillna(0)\n",
    "customers_short['ADDRESSZIPCODE'] = customers_short['ADDRESSZIPCODE'].astype(int)\n",
    "customers_short['ADDRESSZIPCODE'] = customers_short['ADDRESSZIPCODE'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in = pd.merge(\n",
    "    rdnet_in,\n",
    "    customers_short,\n",
    "    how=\"inner\",\n",
    "    on=None,\n",
    "    left_on='STOPLOCATIONID',\n",
    "    right_on='CUSTOMERACCOUNT',\n",
    "    left_index=False,\n",
    "    right_index=False,\n",
    "    sort=True,\n",
    "    suffixes=(\"_x\", \"_y\"),\n",
    "    copy=True,\n",
    "    indicator=False,\n",
    "    validate=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in.rename(columns={'ADDRESSZIPCODE':'STOPPOSTALCODE'}, inplace=True)\n",
    "rdnet_in.drop(columns={'CUSTOMERACCOUNT', 'ORGANIZATIONNAME'}, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "rdnet_in = rdnet_in.drop_duplicates(keep='first');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rdnet_in.sort_values(['ORIGINLOCATIONID','ROADNETROUTE']).to_csv('data/roadnet/try1.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split file into n files, each with a different ORIGINLOCATIONID\n",
    "- Read csv file with ORIGINLOCATIONIDs\n",
    "- Generate a dataframe with the unique list of warehouses\n",
    "- Add a column (Group) to that dataframe where the warehouses are assigned into n groups\n",
    "- Generate n output files, each with ORIGINLOCATIONID as from the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remember to update data/roadnet/sessionIDs.csv with the list of session IDs.  This will determine how the Roadnet inbound file will be split.\n"
     ]
    }
   ],
   "source": [
    "print('Remember to update data/roadnet/sessionIDs.csv with the list of session IDs.  This will determine how the Roadnet inbound file will be split.')\n",
    "input('Press \"Enter\" to continue. ')\n",
    "sessionids = pd.read_csv('data/roadnet/sessionIDs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting inbound files per sessionID\n"
     ]
    }
   ],
   "source": [
    "print(\"Splitting inbound files per sessionID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessionids_list = sessionids.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_warehouses_np = rdnet_in['ORIGINLOCATIONID'].unique()\n",
    "unique_warehouses_df = pd.DataFrame(unique_warehouses_np)\n",
    "number_of_warehouses = len(rdnet_in['ORIGINLOCATIONID'].unique())\n",
    "number_of_sessionIDs = len(sessionids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if number_of_warehouses < number_of_sessionIDs:\n",
    "    raise SystemExit(\"There are more sessionIDs than warehouses - some of the output files will have no lines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in['WH_route_combination'] = rdnet_in['ORIGINLOCATIONID'].astype(str) + rdnet_in['ROADNETROUTE'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New code to do a more equal distrobution of warehouses (itv of lines) over the sessions. \n",
    "# If there are 8 sessionIDs (i.e. virtual users), do it the following way:\n",
    "# Step through warehouses from one with most lines to one with fewest lines\n",
    "# Assign sequentially to the users 1 to 8\n",
    "# Then, assign the remaining in reverse order from 8 to 1, continue allocating in descending quantity. Wrap back to 8 if needed.\n",
    "\n",
    "#x = rdnet_in.groupby(['ORIGINLOCATIONID','ROADNETROUTE']).agg({'INVENTTRANSID': 'count', 'WH_route_combination': 'first'}).sort_values('INVENTTRANSID',ascending=False).reset_index().copy()\n",
    "x = rdnet_in.groupby(['WH_route_combination']).agg({'INVENTTRANSID': 'count'}).sort_values('INVENTTRANSID',ascending=False).reset_index().copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['sessionID'] = ''\n",
    "user = 0\n",
    "user_ascending = True\n",
    "for i in range(len(x)):\n",
    "    if user_ascending == True and user < number_of_sessionIDs:\n",
    "        user = user + 1\n",
    "\n",
    "    if user_ascending == False and user <= number_of_sessionIDs:\n",
    "        if user > 1:\n",
    "            user = user - 1\n",
    "        else:\n",
    "            user = number_of_sessionIDs\n",
    "\n",
    "    if user_ascending == True and user == number_of_sessionIDs:\n",
    "        user_ascending = False\n",
    "        user = number_of_sessionIDs           \n",
    "\n",
    "    x.at[i, 'sessionID'] = str(sessionids_list[user-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.drop(columns={'INVENTTRANSID'}, inplace=True, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge back the warehouse-based split into the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in = pd.merge(\n",
    "    rdnet_in,\n",
    "    x,\n",
    "    how=\"inner\",\n",
    "    on=None,\n",
    "    left_on='WH_route_combination',\n",
    "    right_on='WH_route_combination',\n",
    "    left_index=False,\n",
    "    right_index=False,\n",
    "    sort=True,\n",
    "    suffixes=(\"_x\", \"_y\"),\n",
    "    copy=True,\n",
    "    indicator=False,\n",
    "    validate=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in.drop(columns={'WH_route_combination'}, inplace=True, axis=1)\n",
    "rdnet_in.rename(columns={'sessionID':'DYNAMICSRETRIEVALSESSIONID'}, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing CSV files per sessionID\n"
     ]
    }
   ],
   "source": [
    "print(\"Writing CSV files per sessionID\")\n",
    "# Clean up the folder where the inbound files are to be stored\n",
    "path = \"data/roadnet/inbound/\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "for i in range(0,len(dir_list)):\n",
    "    xml_file = path+dir_list[i]\n",
    "    os.remove(xml_file)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14017/1727086307.py:5: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  df_temp.to_csv(filename+'.csv',index=False, line_terminator='\\r\\n')\n"
     ]
    }
   ],
   "source": [
    "for sessionID in sessionids_list:\n",
    "    mask = (rdnet_in['DYNAMICSRETRIEVALSESSIONID'] == sessionID[0])\n",
    "    df_temp = rdnet_in[mask].copy()\n",
    "    filename = 'data/roadnet/inbound/rdnet_inbound_'+sessionID[0]\n",
    "    df_temp.to_csv(filename+'.csv',index=False, line_terminator='\\r\\n')    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change nl to cr-nl in the CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' def fix_newlines(fname, fnum):\\n\\n    with open(fname, \\'r\\') as fr:\\n        # reading line by line\\n        lines = fr.readlines()\\n        last_line = len(lines)\\n\\n    for line in lines:\\n        replaced_line = re.sub(\"\\n\", \"\\r\\n\", line)\\n        #print(fnum,line)\\n        outfile = fname[:-4] + \\'_fixed.csv\\'\\n        with open(outfile, \\'a\\') as fw:\\n            fw.write(replaced_line)    \\n\\n    return '"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" def fix_newlines(fname, fnum):\n",
    "\n",
    "    with open(fname, 'r') as fr:\n",
    "        # reading line by line\n",
    "        lines = fr.readlines()\n",
    "        last_line = len(lines)\n",
    "\n",
    "    for line in lines:\n",
    "        replaced_line = re.sub(\"\\n\", \"\\r\\n\", line)\n",
    "        #print(fnum,line)\n",
    "        outfile = fname[:-4] + '_fixed.csv'\n",
    "        with open(outfile, 'a') as fw:\n",
    "            fw.write(replaced_line)    \n",
    "\n",
    "    return \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' path = \"data/roadnet/inbound/\"\\ndir_list = os.listdir(path)\\n\\nfor i in range(0,len(dir_list)):\\n    csv_file = path+dir_list[i]\\n    fix_newlines(csv_file,i)\\n    os.remove(path+dir_list[i]) '"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" path = \"data/roadnet/inbound/\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "for i in range(0,len(dir_list)):\n",
    "    csv_file = path+dir_list[i]\n",
    "    fix_newlines(csv_file,i)\n",
    "    os.remove(path+dir_list[i]) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Roadnet order lines were split by warehouse and route ID, into 1 files.  The lines were split as follows:\n",
      "                            INVENTTRANSID\n",
      "DYNAMICSRETRIEVALSESSIONID               \n",
      "ZA1-000000918                         945\n"
     ]
    }
   ],
   "source": [
    "print('The Roadnet order lines were split by warehouse and route ID, into ' + str(number_of_sessionIDs) + ' files.  The lines were split as follows:')\n",
    "print(rdnet_in.groupby(['DYNAMICSRETRIEVALSESSIONID']).agg({'INVENTTRANSID': 'count'}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdnet_out['WAREHOUSEID'].nunique()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of script"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
