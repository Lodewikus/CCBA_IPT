{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lxml\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script summary\n",
    "- Import several Excel files from D365 that lists sales orders with Load IDs and consolidate them in one dataframe\n",
    "- Ask the user how many sessions this should be split into\n",
    "- Split the dataframe into n x csv files\n",
    "- Convert the CSV files to Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up the xml_prep folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/rel_to_wh/outbound_to_EA/\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "for i in range(0,len(dir_list)):\n",
    "    xml_file = path+dir_list[i]\n",
    "    os.remove(xml_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import files from D365 containing sales order lines with Load IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/rel_to_wh/inbound_from_D365/\"\n",
    "dir_list = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadfiles_concat = pd.read_excel(path+dir_list[0])\n",
    "try:\n",
    "    loadfiles_concat.rename(columns={'Load ID': 'LoadID'}, inplace=True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1data/rel_to_wh/inbound_from_D365/ZA1-000000811.xlsx\n",
      "2data/rel_to_wh/inbound_from_D365/ZA1-000000799.xlsx\n",
      "3data/rel_to_wh/inbound_from_D365/ZA1-000000806.xlsx\n",
      "4data/rel_to_wh/inbound_from_D365/ZA1-000000812.xlsx\n",
      "5data/rel_to_wh/inbound_from_D365/ZA1-000000805.xlsx\n",
      "6data/rel_to_wh/inbound_from_D365/ZA1-000000809.xlsx\n",
      "7data/rel_to_wh/inbound_from_D365/ZA1-000000807.xlsx\n",
      "8data/rel_to_wh/inbound_from_D365/ZA1-000000802.xlsx\n",
      "9data/rel_to_wh/inbound_from_D365/ZA1-000000804.xlsx\n",
      "10data/rel_to_wh/inbound_from_D365/ZA1-000000801.xlsx\n",
      "11data/rel_to_wh/inbound_from_D365/ZA1-000000803.xlsx\n",
      "12data/rel_to_wh/inbound_from_D365/ZA1-000000810.xlsx\n",
      "13data/rel_to_wh/inbound_from_D365/ZA1-000000808.xlsx\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,len(dir_list)):\n",
    "    xml_file = path+dir_list[i]\n",
    "    print(str(i)+xml_file)\n",
    "    temp = pd.read_excel(path+dir_list[i])\n",
    "    try:\n",
    "        temp.rename(columns={'Load ID': 'LoadID'}, inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    loadfiles_concat = pd.concat([loadfiles_concat, temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads_to_wh = loadfiles_concat[['LoadID','Description']].copy()\n",
    "loads_to_wh.drop(columns={'Description'}, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads_to_wh.drop_duplicates(keep='first',inplace=True)\n",
    "loads_to_wh = loads_to_wh.dropna()\n",
    "loads_to_wh.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads_to_wh['LoadID'] = loads_to_wh['LoadID'].astype(int)\n",
    "loads_to_wh['LoadID'] = loads_to_wh['LoadID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LoadID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2200011903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2200011989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2200011845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2200011846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2200011847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2200011956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2200011957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2200011988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2200011984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2200011985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         LoadID\n",
       "0    2200011903\n",
       "1    2200011989\n",
       "2    2200011845\n",
       "3    2200011846\n",
       "4    2200011847\n",
       "..          ...\n",
       "140  2200011956\n",
       "141  2200011957\n",
       "142  2200011988\n",
       "143  2200011984\n",
       "144  2200011985\n",
       "\n",
       "[145 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loads_to_wh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data among the number of user sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_str = input('Enter the number of files into which the loads must be split')\n",
    "files = int(files_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in range(1,files+1):\n",
    "    with open('data/rel_to_wh/outbound_to_EA/wh' + str(file) + '.csv', 'a') as fw:        \n",
    "        fw.write('LoadID'+'\\n')\n",
    "\n",
    "file = 0\n",
    "for i in range(len(loads_to_wh)):\n",
    "    if file <= files-1:\n",
    "        file = file + 1\n",
    "    else:\n",
    "        file = 1\n",
    "    with open('data/rel_to_wh/outbound_to_EA/wh' + str(file) + '.csv', 'a') as fw:        \n",
    "        fw.write(str(loads_to_wh.loc[i, \"LoadID\"])+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now convert the CSV files into Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/rel_to_wh/outbound_to_EA/\"\n",
    "dir_list = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21 user - Release to warehouse , picking and despatch (Roadnet loads).xlsx\n",
    "\n",
    "for i in range(0,len(dir_list)):\n",
    "    excel_file = path+str(i+1)+' user - Release to warehouse , picking and despatch (Roadnet loads).xlsx'\n",
    "    #print(str(i)+xml_file)\n",
    "    temp = pd.read_csv(path+dir_list[i])\n",
    "    temp.to_excel(excel_file, index=False)\n",
    "    os.remove(path+dir_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raise SystemExit(\"Stop right here!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
