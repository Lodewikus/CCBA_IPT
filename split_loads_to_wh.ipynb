{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lxml\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads_to_wh = pd.read_csv('data/rel_to_wh/Loads created_concatenated.csv')\n",
    "loads_to_wh = pd.read_excel('data/rel_to_wh/Loads created_concatenated.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads_to_wh.drop_duplicates(keep='first',inplace=True)\n",
    "loads_to_wh.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 153 entries, 0 to 152\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   Load    153 non-null    int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 1.3 KB\n"
     ]
    }
   ],
   "source": [
    "loads_to_wh.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_str = input('Enter the number of files into which the loads must be split')\n",
    "files = int(files_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loads_to_wh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_per_file = int(len(loads_to_wh)/(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenum = 0\n",
    "for i in range(len(loads_to_wh)):\n",
    "    if i % lines_per_file == 0:\n",
    "        filenum = filenum + 1\n",
    "    if filenum > files:\n",
    "        filenum = files\n",
    "    # print(i)\n",
    "    # print(str(loads_to_wh.loc[i, \"Load\"]))\n",
    "    with open('data/rel_to_wh/wh' + str(filenum) + '.csv', 'a') as fw:        \n",
    "         fw.write(str(loads_to_wh.loc[i, \"Load\"])+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix manually prepared files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/fix_wh_files/\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "# for i in range(0,len(dir_list)):\n",
    "#     file = path+dir_list[i]\n",
    "#     os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadfiles_concat = pd.read_excel(path+dir_list[0])\n",
    "try:\n",
    "    loadfiles_concat.rename(columns={'Load ID': 'LoadID'}, inplace=True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1data/fix_wh_files/14 user - Release to warehouse , picking and despatch (Roadnet loads).xlsx\n",
      "2data/fix_wh_files/12 user - Release to warehouse , picking and despatch (Roadnet loads).xlsx\n",
      "3data/fix_wh_files/8 user - Release to warehouse , picking and despatch (Roadnet loads).xlsx\n",
      "4data/fix_wh_files/5 user - Release to warehouse , picking and despatch (Roadnet loads).xlsx\n",
      "5data/fix_wh_files/15 user - Release to warehouse , picking and despatch (Roadnet loads).xlsx\n",
      "6data/fix_wh_files/7 user - Release to warehouse , picking and despatch (Roadnet loads).xlsx\n",
      "7data/fix_wh_files/17 user - Release to warehouse , picking and despatch (Roadnet loads).xlsx\n",
      "8data/fix_wh_files/9 user - Release to warehouse , picking and despatch (Roadnet loads).xlsx\n",
      "9data/fix_wh_files/13 user - Release to warehouse , picking and despatch (Roadnet loads).xlsx\n",
      "10data/fix_wh_files/4 user - Release to warehouse , picking and despatch (Roadnet loads).xlsx\n",
      "11data/fix_wh_files/19 user - Release to warehouse , picking and despatch (Roadnet loads).xlsx\n",
      "12data/fix_wh_files/18 user - Release to warehouse , picking and despatch (Roadnet loads).xlsx\n",
      "13data/fix_wh_files/23 user - Release to warehouse  picking and despatch (Roadnet loads).xlsx\n",
      "14data/fix_wh_files/24 user - Release to warehouse  picking and despatch (Roadnet loads).xlsx\n",
      "15data/fix_wh_files/16 user - Release to warehouse , picking and despatch (Roadnet loads).xlsx\n",
      "16data/fix_wh_files/20 user - Release to warehouse , picking and despatch (Roadnet loads).xlsx\n",
      "17data/fix_wh_files/3 user - Release to warehouse , picking and despatch (Roadnet loads).xlsx\n",
      "18data/fix_wh_files/28 user - Release to warehouse  picking and despatch (Roadnet loads).xlsx\n",
      "19data/fix_wh_files/6 user - Release to warehouse , picking and despatch (Roadnet loads).xlsx\n",
      "20data/fix_wh_files/2 user - Release to warehouse , picking and despatch (Roadnet loads).xlsx\n",
      "21data/fix_wh_files/11 user - Release to warehouse , picking and despatch (Roadnet loads).xlsx\n",
      "22data/fix_wh_files/10 user - Release to warehouse , picking and despatch (Roadnet loads).xlsx\n",
      "23data/fix_wh_files/22 user - Release to warehouse  picking and despatch (Roadnet loads).xlsx\n",
      "24data/fix_wh_files/26 user - Release to warehouse  picking and despatch (Roadnet loads).xlsx\n",
      "25data/fix_wh_files/1 user - Release to warehouse , picking and despatch (Roadnet loads).xlsx\n",
      "26data/fix_wh_files/25 user - Release to warehouse  picking and despatch (Roadnet loads).xlsx\n",
      "27data/fix_wh_files/27 user - Release to warehouse  picking and despatch (Roadnet loads).xlsx\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,len(dir_list)):\n",
    "    xml_file = path+dir_list[i]\n",
    "    print(str(i)+xml_file)\n",
    "    temp = pd.read_excel(path+dir_list[i])\n",
    "    try:\n",
    "        temp.rename(columns={'Load ID': 'LoadID'}, inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    loadfiles_concat = pd.concat([loadfiles_concat, temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadfiles_concat.rename(columns={'LoadID': 'Load'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadfiles_concat.drop_duplicates(keep='first',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadfiles_concat.to_excel('data/fix_wh_files/loads_consolidated.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
