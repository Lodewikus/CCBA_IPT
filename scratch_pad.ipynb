{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lxml\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pyodbc\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get EA script history in JSON format via the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_headers  = {\"Authorization\": \"Gt4qkl1ahFDcFyQwfjMBYT0utbLD4STHQjWdIXzsYH8v3w29M6Tm6tVKI0uMj6Qh\", \"Content-Type\": \"application/json\"}\n",
    "url = 'https://ea.executive.automats.app/api/bi/scripts?withHistory=true'\n",
    "\n",
    "resp = requests.get(url, headers = custom_headers, verify=False)\n",
    "print(resp.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = json.loads(resp.text)\n",
    "json_text = json.dumps(json_data, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove('data/execution/try.json')\n",
    "except:\n",
    "    print('File does not exist')\n",
    "\n",
    "with open('data/execution/try.json', 'w') as fw:\n",
    "    fw.write(json_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove invalid characters from the inbound JSON data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove('data/execution/script_history_fixed.json')\n",
    "except:\n",
    "    print('File does not exist')\n",
    "\n",
    "#with open('data/execution/script_history.json', 'r') as fr:\n",
    "with open('data/execution/try.json', 'r') as fr:    \n",
    "    # reading line by line\n",
    "    lines = fr.readlines()\n",
    "    last_line = len(lines)\n",
    "    print(len(lines))\n",
    "    \n",
    "    for line in lines:\n",
    "        line = re.sub(\"\\u0003\", \"\", line)\n",
    "        with open('data/execution/script_history_fixed.json', 'a') as fw:\n",
    "            fw.write(line) \n",
    "\n",
    "# Previous runtime = 13.8s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the multilevel JSON into a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/execution/script_history_fixed.json')\n",
    "data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove('data/execution/check_structure.csv')\n",
    "except:\n",
    "    print('File does not exist')\n",
    "with open('data/execution/check_structure.csv', 'a') as fw:\n",
    "    #line = 'topProjectName,name,sessionId,executionLogsId,scriptId,scriptName,script_status,label,step_state,step_status,startTime,endTime,duration,lineNum,StepLogsId,takeScreenshots,screenshotsOnlyOnInterruption\\n'\n",
    "    line = 'topProjectName,name,sessionId,executionLogsId,scriptId,scriptName,script_status,label,step_state,step_status,startTime,endTime,duration,lineNum,StepLogsId\\n'\n",
    "    fw.write(line)\n",
    "    i = 0\n",
    "    for level1 in data:\n",
    "        for key, value in level1.items():\n",
    "            #if i == 100: break\n",
    "            i = i + 1\n",
    "            #takeScreenshots_str = str(level1['takeScreenshots'])\n",
    "            #screenshotsOnlyOnInterruption_str = str(level1['screenshotsOnlyOnInterruption'])            \n",
    "            try:\n",
    "                executionLogs_str = json.dumps(level1['executionLogs'])\n",
    "                executionLogs_json = json.loads(executionLogs_str)\n",
    "                for level2 in executionLogs_json:\n",
    "                    for key2, value2 in level2.items():\n",
    "                        #try:\n",
    "                        executionStepLogs_str = json.dumps(level2['executionStepLogs'])\n",
    "                        executionStepLogs_json = json.loads(executionStepLogs_str)\n",
    "                        if key2 == 'executionStepLogs':\n",
    "                            records_no_str = str(i)\n",
    "                            topProjectName = str(level1['topProjectName'])\n",
    "                            name_str = str(level1['name'])\n",
    "                            # Remove any commas from name \n",
    "                            check = (',' in name_str)\n",
    "                            if check == True:\n",
    "                                name_str = re.sub(',', ';', name_str)                            \n",
    "                            sessionId_str = str(level2['sessionId'])\n",
    "                            id_str = str(level2['id'])\n",
    "                            scriptId_str = str(level2['scriptId'])\n",
    "                            scriptName_str = str(level2['scriptName'])\n",
    "                            # Remove any commas from scriptName \n",
    "                            check = (',' in scriptName_str)\n",
    "                            if check == True:\n",
    "                                scriptName_str = re.sub(',', ';', scriptName_str)                             \n",
    "                            state_str = str(level2['state'])\n",
    "                            status2_str = str(level2['status'])\n",
    "                            lastIssues_str = str(level2['lastIssues'])\n",
    "                            # Remove any commas from lastIssues_str\n",
    "                            check = (',' in lastIssues_str)\n",
    "                            if check == True:\n",
    "                                lastIssues_str = re.sub(',', ';', lastIssues_str)\n",
    "\n",
    "\n",
    "                            for level3 in executionStepLogs_json:\n",
    "                                #for key3, value3 in level3.items():\n",
    "                                status3_str = str(level3['status'])\n",
    "                                label_str = str(level3['label'])\n",
    "                                \n",
    "                                # These lines replace long text test step labels with short text (that does not wrap)\n",
    "                                check = ('Click Dynamics 365' in label_str)\n",
    "                                if check == True:\n",
    "                                    label_str = 'Click Dynamics 365'\n",
    "                                check = ('Click Sales Hub' in label_str)\n",
    "                                if check == True:\n",
    "                                    label_str = 'Click Sales Hub'\n",
    "                                check = ('Type value function eaExecuteVariableValue()' in label_str)\n",
    "                                if check == True:\n",
    "                                    label_str = 'Type value function eaExecuteVariableValue()'\n",
    "                                check = ('Select from function eaExecuteVariableValue()' in label_str)\n",
    "                                if check == True:\n",
    "                                    label_str = 'Select from function eaExecuteVariableValue()'                                    \n",
    "                                check = ('Select lookup values function eaExecuteVariableValue()' in label_str)\n",
    "                                if check == True:\n",
    "                                    label_str = 'Select lookup values function eaExecuteVariableValue()'\n",
    "                                # Remove any commas from label_str \n",
    "                                check = (',' in label_str)\n",
    "                                if check == True:\n",
    "                                    label_str = re.sub(',', ';', label_str)\n",
    "                                # Now replace all newlines that remain in label_str\n",
    "                                check = ('\\n' in label_str)\n",
    "                                if check == True:\n",
    "                                    label_str = re.sub('\\n', '/nl/', label_str)\n",
    "                                # Done with replacing text\n",
    "\n",
    "                                startTime_str = str(level3['startTime'])\n",
    "                                endTime_str = str(level3['endTime'])\n",
    "                                duration_str = str(level3['duration'])\n",
    "                                lineNum_str = str(level3['lineNum'])\n",
    "                                StepLogs_id_str = str(level3['id'])\n",
    "\n",
    "                                #line = topProjectName+','+name_str+','+sessionId_str+','+id_str+','+scriptId_str+','+scriptName_str+','+status2_str+','+label_str+','+state_str+','+status3_str+','+startTime_str+','+endTime_str+','+duration_str+','+lineNum_str+','+StepLogs_id_str+','+takeScreenshots_str+','+screenshotsOnlyOnInterruption_str+'\\n'\n",
    "                                line = topProjectName+','+name_str+','+sessionId_str+','+id_str+','+scriptId_str+','+scriptName_str+','+status2_str+','+label_str+','+state_str+','+status3_str+','+startTime_str+','+endTime_str+','+duration_str+','+lineNum_str+','+StepLogs_id_str+'\\n'\n",
    "                                fw.write(line)\n",
    "                            # except:\n",
    "                            #     print('Exception on Level2 for Level1 item '+str(i))\n",
    "            except:\n",
    "                #print('Exception for Level1 item '+str(i))\n",
    "                pass\n",
    "    print('Processed '+str(i)+' items')           \n",
    "\n",
    "    # Previous runtime = 4m 19.5s     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the denormalized CSV file into a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_740/2960382116.py:1: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data/execution/check_structure.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/execution/check_structure.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2528057 entries, 0 to 2528056\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count    Dtype \n",
      "---  ------           --------------    ----- \n",
      " 0   topProjectName   2528057 non-null  object\n",
      " 1   name             2528057 non-null  object\n",
      " 2   sessionId        2528057 non-null  object\n",
      " 3   executionLogsId  2528057 non-null  int64 \n",
      " 4   scriptId         2528057 non-null  int64 \n",
      " 5   scriptName       2528057 non-null  object\n",
      " 6   script_status    2528057 non-null  object\n",
      " 7   label            2528057 non-null  object\n",
      " 8   step_state       2528057 non-null  object\n",
      " 9   step_status      2528057 non-null  object\n",
      " 10  startTime        2528057 non-null  object\n",
      " 11  endTime          2528057 non-null  object\n",
      " 12  duration         2528057 non-null  object\n",
      " 13  lineNum          2528057 non-null  int64 \n",
      " 14  StepLogsId       2528057 non-null  int64 \n",
      "dtypes: int64(4), object(11)\n",
      "memory usage: 289.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df = df.reset_index(drop=True)\n",
    "df.rename(columns={'label':'StepLabel'}, inplace=True)\n",
    "df.rename(columns={'name':'testName'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df['startTime'] == 'None') \n",
    "df['startTime'].mask(mask,'2022-01-01T00:00:00.000Z',inplace=True)\n",
    "df['startTime'] = pd.to_datetime(df['startTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df['endTime'] == 'None') \n",
    "df['endTime'].mask(mask,'2022-01-01T00:00:00.000Z',inplace=True)\n",
    "df['endTime'] = pd.to_datetime(df['endTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df['duration'] == 'None') \n",
    "df['duration'].mask(mask,'0',inplace=True)\n",
    "df['duration'] = pd.to_numeric(df['duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['duration_sec'] = df.duration/1000\n",
    "df['duration_mins'] = df.duration/1000/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['startTime'], format='%Y-%m-%d').dt.date\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the dataset for the relevant date(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.query(\"date == '2023-01-26'\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop_duplicates(keep='first')\n",
    "df2 = df2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" def summary(x):\n",
    "    runs = x['executionLogsId'].nunique()\n",
    "    runs = float(runs)\n",
    "    duration = x['duration'].sum()/1000\n",
    "    mean_s = x['duration'].mean()/1000\n",
    "    count = duration/mean_s\n",
    "    result = {\n",
    "        'aggr_duration': duration,\n",
    "        'aggr_duration_minutes': duration/60,\n",
    "        'runs': runs,\n",
    "        'mean_sec': duration/runs,\n",
    "        'mean_minutes': duration/runs/60 ,\n",
    "        'steps': count\n",
    "    }\n",
    "    return pd.Series(result).round(1)\n",
    "\n",
    "#df2.groupby(['scriptName','sessionId']).apply(summary).to_html('data/execution/result.html')\n",
    "df2.groupby(['testName', 'executionLogsId']).apply(summary).to_html('data/execution/result.html')\n",
    "df2.groupby(['testName', 'executionLogsId']).apply(summary).to_excel('data/execution/result_groupby.xlsx')\n",
    "df2.groupby(['testName', 'executionLogsId']).agg({'executionLogsId': {'nunique'}, 'duration' : {'sum'}})\n",
    "#df2.groupby(['testName']).apply(summary).to_html('data/execution/result.html') \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a column to indicate Runs of each test script\n",
    "As there is no other field available via the API, this field is generated each time the lineNum == 1.  This assumes that there will always be a step 1 in every test case.\n",
    "Before this can be done, first sort the whole dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.sort_values(by=['executionLogsId','StepLogsId'], inplace=True)\n",
    "df2 = df2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_740/2202998152.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['run2'][idx] = run\n"
     ]
    }
   ],
   "source": [
    "df2['run2'] = 0\n",
    "run = 0\n",
    "for idx in df2.index:\n",
    "    if df2['lineNum'][idx] == 1:\n",
    "        run = run + 1\n",
    "    df2['run2'][idx] = run"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a field to indicate where test scripts have run to the last step of the script\n",
    "This assumes that the last step is \"End script\"\n",
    "First sort the dataframe by Runs\n",
    "Then add a new text field that is a concatenation of all the step labels for each run\n",
    "Finally, check which of those strings contain the text \"End script\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.sort_values(by=['executionLogsId','StepLogsId','run2'], inplace=True)\n",
    "#df2 = df2.reset_index(drop=True)\n",
    "df2.sort_values(by=['run2'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['step_list'] = ''\n",
    "df2['run_status'] = ''\n",
    "df2['step_error'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = -1\n",
    "for idx in df2.index:\n",
    "    #if run == 10: break\n",
    "    if run != df2['run2'][idx]:\n",
    "        loop_steplist = df2['StepLabel'][idx]\n",
    "        df2['step_list'][idx] = loop_steplist\n",
    "    else:\n",
    "        loop_steplist = loop_steplist + df2['StepLabel'][idx]\n",
    "        df2['step_list'][idx] = loop_steplist\n",
    "    run = df2['run2'][idx]\n",
    "    #print(run,df2['run2'][idx],df2['StepLabel'][idx],df2['step_list'][idx])\n",
    "    \n",
    "    if df2['step_status'][idx] == 'ERROR':\n",
    "        df2['step_error'][idx] = 'ERROR'            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['run_status'] = 'Script run incomplete'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df2['step_list'].str.contains('End script'))\n",
    "df2['run_status'].mask(mask,'Script completed',inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a column to indicate scripts where at least one step status is \"Error\".\n",
    "This is necessary, as the script status is sometimes Success even where a step terminates in \"Error\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate an output file in CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('data/execution/result.csv',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From here on the script is disabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert this to prevent the cells below from trying to write to the sql table\n",
    "raise SystemExit(\"Stop right here!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get ready to export to SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df['date'] > '2023-01-10')\n",
    "#df.loc[(df['date'] > '2023-01-10')]\n",
    "df = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://learn.microsoft.com/en-us/sql/machine-learning/data-exploration/python-dataframe-pandas?view=sql-server-ver16\n",
    "# Some other example server values are\n",
    "# server = 'localhost\\sqlexpress' # for a named instance\n",
    "# server = 'myserver,port' # to specify an alternate port\n",
    "server = 'tcp:csazniptlsql01.database.windows.net,1433' \n",
    "database = 'CSAZN-INT-IPT-L-DSQ-01' \n",
    "username = 'ccbaadmin' \n",
    "password = '@FireBase123' \n",
    "# ENCRYPT defaults to yes starting in ODBC Driver 18. It's good to always specify ENCRYPT=yes on the client side to avoid MITM attacks.\n",
    "cnxn = pyodbc.connect('DRIVER={ODBC Driver 18 for SQL Server};SERVER='+server+';DATABASE='+database+';ENCRYPT=yes;UID='+username+';PWD='+ password)\n",
    "cursor = cnxn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cursor = cnxn.cursor()\n",
    "\n",
    "# cursor.execute('''\n",
    "# \t\tCREATE TABLE ea_script_history (\n",
    "# \t\t\trecords_no int,\n",
    "#             topProjectName nvarchar(255),\n",
    "#             testName nvarchar(255),\n",
    "#             sessionId nvarchar(255),\n",
    "#             id int,\n",
    "#             scriptId int,\n",
    "#             scriptName nvarchar(255),\n",
    "#             state nvarchar(255),\n",
    "#             status nvarchar(255),\n",
    "#             StepLabel nvarchar(255),\n",
    "#             startTime datetime,\n",
    "#             endTime datetime,\n",
    "#             duration int,\n",
    "#             lineNum int,\n",
    "#             StepLogs_id int\n",
    "# \t\t\t)\n",
    "#                ''')\n",
    "\n",
    "# cnxn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnxn = pyodbc.connect('DRIVER={ODBC Driver 18 for SQL Server};SERVER='+server+';DATABASE='+database+';ENCRYPT=yes;UID='+username+';PWD='+ password)\n",
    "cursor = cnxn.cursor()\n",
    "# Insert Dataframe into SQL Server:\n",
    "i = 0\n",
    "for index, row in df.iterrows():\n",
    "     cursor.execute(\"INSERT INTO ea_script_history (records_no,topProjectName,testName,sessionId,id,scriptId,scriptName,state,status,StepLabel,startTime,endTime,duration,lineNum,StepLogs_id) values(?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)\", row.records_no, row.topProjectName, row.testName, row.sessionId, row.id, row.scriptId, row.scriptName, row.state, row.status, row.StepLabel, row.startTime, row.endTime, row.duration, row.lineNum, row.StepLogs_id)\n",
    "     i = i + 1\n",
    "     if i == 1000:\n",
    "          i = 0\n",
    "          cnxn.commit()          \n",
    "cnxn.commit()\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnxn = pyodbc.connect('DRIVER={ODBC Driver 18 for SQL Server};SERVER='+server+';DATABASE='+database+';ENCRYPT=yes;UID='+username+';PWD='+ password)\n",
    "# cursor = cnxn.cursor()\n",
    "# # Insert Dataframe into SQL Server:\n",
    "# for index, row in df.iterrows():\n",
    "#      cursor.execute(\"INSERT INTO ea_script_history (startTime) values(?)\", row.startTime)\n",
    "# cnxn.commit()\n",
    "# cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all the rows in the SQl script history table\n",
    "cursor = cnxn.cursor()\n",
    "cursor.execute(\"DELETE FROM ea_script_history\")\n",
    "cnxn.commit()\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the SQl script history table (it must be re-created)\n",
    "cursor = cnxn.cursor()\n",
    "cursor.execute(\"DROP Table ea_script_history\")\n",
    "#cursor.execute(\"DROP Table temp_table\")\n",
    "cnxn.commit()\n",
    "cursor.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
