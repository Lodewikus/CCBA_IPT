{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lxml\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime, date, time\n",
    "#import pyodbc\n",
    "import requests\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get EA script history in JSON format via the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wikus/code/CCBA_IPT/ccba_env/lib/python3.8/site-packages/urllib3/connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ea.executive.automats.app'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "custom_headers  = {\"Authorization\": \"Gt4qkl1ahFDcFyQwfjMBYT0utbLD4STHQjWdIXzsYH8v3w29M6Tm6tVKI0uMj6Qh\", \"Content-Type\": \"application/json\"}\n",
    "url = 'https://ea.executive.automats.app/api/bi/scripts?withHistory=true'\n",
    "\n",
    "resp = requests.get(url, headers = custom_headers, verify=False)\n",
    "print(resp.status_code)\n",
    "\n",
    "# Previous runtime = 1min 26s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = json.loads(resp.text)\n",
    "json_text = json.dumps(json_data, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File does not exist\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.remove('data/execution/try.json')\n",
    "except:\n",
    "    print('File does not exist')\n",
    "\n",
    "with open('data/execution/try.json', 'w') as fw:\n",
    "    fw.write(json_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove invalid characters from the inbound JSON data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File does not exist\n",
      "11909843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11909843/11909843 [34:46<00:00, 5708.99it/s] \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.remove('data/execution/script_history_fixed.json')\n",
    "except:\n",
    "    print('File does not exist')\n",
    "\n",
    "#with open('data/execution/script_history.json', 'r') as fr:\n",
    "with open('data/execution/try.json', 'r') as fr:    \n",
    "    # reading line by line\n",
    "    lines = fr.readlines()\n",
    "    last_line = len(lines)\n",
    "    print(len(lines))\n",
    "    \n",
    "    for line in tqdm(lines):\n",
    "        line = re.sub(\"\\u0003\", \"\", line)\n",
    "        with open('data/execution/script_history_fixed.json', 'a') as fw:\n",
    "            fw.write(line) \n",
    "\n",
    "# Previous runtime = 2m 9.2s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the multilevel JSON into a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/execution/script_history_fixed.json')\n",
    "data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 944/944 [11:06<00:00,  1.42it/s]  \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.remove('data/execution/check_structure.csv')\n",
    "except:\n",
    "    print('File does not exist')\n",
    "with open('data/execution/check_structure.csv', 'a') as fw:\n",
    "    #line = 'topProjectName,name,sessionId,executionLogsId,scriptId,scriptName,script_status,label,step_state,step_status,startTime,endTime,duration,lineNum,StepLogsId,lastIssues\\n'\n",
    "    line = 'topProjectName,name,sessionId,executionLogsId,scriptId,scriptName,script_status,label,step_state,step_status,startTime,endTime,duration,lineNum,StepLogsId\\n'\n",
    "    fw.write(line)\n",
    "    i = 0\n",
    "    for level1 in tqdm(data):\n",
    "        # for key, value in level1.items():\n",
    "        #     #if i == 100: break\n",
    "                     \n",
    "        try:\n",
    "            executionLogs_str = json.dumps(level1['executionLogs'])\n",
    "            executionLogs_json = json.loads(executionLogs_str)\n",
    "            for level2 in executionLogs_json:\n",
    "                for key2, value2 in level2.items():\n",
    "                    #try:\n",
    "                    startTime_str = str(level2['startTime'])\n",
    "                    startTime_str = startTime_str[0:10]\n",
    "                    startTime = datetime.strptime(startTime_str, '%Y-%m-%d')\n",
    "                    oldestHistory = datetime.strptime('2023-02-26', '%Y-%m-%d')\n",
    "                    executionStepLogs_str = json.dumps(level2['executionStepLogs'])\n",
    "                    executionStepLogs_json = json.loads(executionStepLogs_str)\n",
    "                    if key2 == 'executionStepLogs' and startTime >= oldestHistory:\n",
    "\n",
    "                        topProjectName = str(level1['topProjectName'])\n",
    "                        name_str = str(level1['name'])\n",
    "                        # Remove any commas from name \n",
    "                        check = (',' in name_str)\n",
    "                        if check == True:\n",
    "                            name_str = re.sub(',', ';', name_str)                            \n",
    "                        sessionId_str = str(level2['sessionId'])\n",
    "                        id_str = str(level2['id'])\n",
    "                        scriptId_str = str(level2['scriptId'])\n",
    "                        scriptName_str = str(level2['scriptName'])\n",
    "                        # Remove any commas from scriptName \n",
    "                        check = (',' in scriptName_str)\n",
    "                        if check == True:\n",
    "                            scriptName_str = re.sub(',', ';', scriptName_str)                             \n",
    "                        state_str = str(level2['state'])\n",
    "                        status2_str = str(level2['status'])\n",
    "                        # lastIssues_str = str(level2['lastIssues'])\n",
    "                        # Remove any commas from lastIssues_str\n",
    "                        # check = (',' in lastIssues_str)\n",
    "                        # if check == True:\n",
    "                        #     lastIssues_str = re.sub(',', '~', lastIssues_str)\n",
    "                        # check = ('\\n' in lastIssues_str)\n",
    "                        # if check == True:\n",
    "                        #     lastIssues_str = re.sub('\\n', '|', lastIssues_str)                         \n",
    "\n",
    "\n",
    "                        for level3 in executionStepLogs_json:\n",
    "                            \n",
    "                            #for key3, value3 in level3.items():\n",
    "                            status3_str = str(level3['status'])\n",
    "                            label_str = str(level3['label'])\n",
    "                            \n",
    "                            # These lines replace long text test step labels with short text (that does not wrap)\n",
    "                            check = ('Click Dynamics 365' in label_str)\n",
    "                            if check == True:\n",
    "                                label_str = 'Click Dynamics 365'\n",
    "                            check = ('Click Sales Hub' in label_str)\n",
    "                            if check == True:\n",
    "                                label_str = 'Click Sales Hub'\n",
    "                            check = ('Type value function eaExecuteVariableValue()' in label_str)\n",
    "                            if check == True:\n",
    "                                label_str = 'Type value function eaExecuteVariableValue()'\n",
    "                            check = ('Select from function eaExecuteVariableValue()' in label_str)\n",
    "                            if check == True:\n",
    "                                label_str = 'Select from function eaExecuteVariableValue()'                                    \n",
    "                            check = ('Select lookup values function eaExecuteVariableValue()' in label_str)\n",
    "                            if check == True:\n",
    "                                label_str = 'Select lookup values function eaExecuteVariableValue()'\n",
    "                            # Remove any commas from label_str \n",
    "                            check = (',' in label_str)\n",
    "                            if check == True:\n",
    "                                label_str = re.sub(',', ';', label_str)\n",
    "                            # Now replace all newlines that remain in label_str\n",
    "                            check = ('\\n' in label_str)\n",
    "                            if check == True:\n",
    "                                label_str = re.sub('\\n', '/nl/', label_str)\n",
    "                            # Done with replacing text\n",
    "\n",
    "                            startTime_str = str(level3['startTime'])\n",
    "                            endTime_str = str(level3['endTime'])\n",
    "                            duration_str = str(level3['duration'])\n",
    "                            lineNum_str = str(level3['lineNum'])\n",
    "                            StepLogs_id_str = str(level3['id'])\n",
    "\n",
    "                            i = i + 1\n",
    "\n",
    "                            #line = topProjectName+','+name_str+','+sessionId_str+','+id_str+','+scriptId_str+','+scriptName_str+','+status2_str+','+label_str+','+state_str+','+status3_str+','+startTime_str+','+endTime_str+','+duration_str+','+lineNum_str+','+StepLogs_id_str+','+lastIssues_str+'\\n'\n",
    "                            line = topProjectName+','+name_str+','+sessionId_str+','+id_str+','+scriptId_str+','+scriptName_str+','+status2_str+','+label_str+','+state_str+','+status3_str+','+startTime_str+','+endTime_str+','+duration_str+','+lineNum_str+','+StepLogs_id_str+'\\n'\n",
    "                            fw.write(line)\n",
    "                            if level3['id'] == 2:\n",
    "                                print(line)                                \n",
    "                        # except:\n",
    "                        #     print('Exception on Level2 for Level1 item '+str(i))\n",
    "        except:\n",
    "            #print('Exception for Level1 item '+str(i))\n",
    "            pass       \n",
    "\n",
    "    # Previous runtime = 45.1s   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the denormalized CSV file into a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/execution/check_structure.csv')\n",
    "\n",
    "# Previous runtime = 2.2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df = df.reset_index(drop=True)\n",
    "df.rename(columns={'label':'StepLabel'}, inplace=True)\n",
    "df.rename(columns={'name':'testName'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['lastIssues'] = df['lastIssues'].str.replace('|','\\n', regex=False)\n",
    "# df['lastIssues'] = df['lastIssues'].str.replace('~',',', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset = ['testName']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df['startTime'] == 'None') \n",
    "df['startTime'].mask(mask,'2022-01-01T00:00:00.000Z',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df['endTime'] == 'None') \n",
    "df['endTime'].mask(mask,'2022-01-01T00:00:00.000Z',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df['duration'] == 'None') \n",
    "df['duration'].mask(mask,'0',inplace=True)\n",
    "df['duration'] = pd.to_numeric(df['duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['duration_sec'] = df.duration/1000\n",
    "df['duration_mins'] = df.duration/1000/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['startTime'], format='%Y-%m-%d').dt.date\n",
    "df['date'] = pd.to_datetime(df['date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time'] = pd.to_datetime(df['startTime']).dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time_dec'] = df['time'].astype(str)\n",
    "df['time_dec'] = df['time_dec'].str[:5]\n",
    "df['time_dec'] = df['time_dec'].str.replace(':','.')\n",
    "df['time_dec'] = df['time_dec'].astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a column to indicate Runs of each test script\n",
    "As there is no other field available via the API, this field is generated each time the lineNum == 1.  This assumes that there will always be a step 1 in every test case.\n",
    "Before this can be done, first sort the whole dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['executionLogsId','StepLogsId'], inplace=True)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is old code to allocate a 'run' number and increment it every time the lineNum == 1\n",
    "\n",
    "# df['run'] = 0\n",
    "# run = 0\n",
    "# for idx in df.index:\n",
    "#     if df['lineNum'][idx] == 1:\n",
    "#         run = run + 1\n",
    "#     df['run'][idx] = run\n",
    "\n",
    " # Previous runtime = 31.4s    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the new code to allocate a 'run' number and increment it every time the lineNum == 1.  This was generated by ChatGPT based on the code above :-)\n",
    "\n",
    "df['run'] = (df['lineNum'] == 1).cumsum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a field to indicate where test scripts have run to the last step of the script\n",
    "This assumes that the last step is \"End script\"\n",
    "First sort the dataframe by Runs\n",
    "Then add a new text field that is a concatenation of all the step labels for each run\n",
    "Finally, check which of those strings contain the text \"End script\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_np = df.run.unique()\n",
    "end_script_dict = {}\n",
    "for i in runs_np:\n",
    "    end_script_dict[i] = 'Script stopped'\n",
    "step_error_dict = {}\n",
    "for i in runs_np:\n",
    "    step_error_dict[i] = 'No step errors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['run'], inplace=True)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in df.index:\n",
    "    #if run == 10: break\n",
    "    run = df['run'][idx]\n",
    "    if df['StepLabel'][idx] == 'End script':\n",
    "        end_script_dict[run] = 'Script completed'\n",
    "    if df['step_status'][idx] == 'ERROR':\n",
    "        step_error_dict[run] = 'One or more step errors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_script_df = pd.DataFrame.from_dict(end_script_dict,orient ='index',columns=['script_completion'])\n",
    "end_script_df.reset_index(inplace=True)\n",
    "end_script_df.rename(columns={'index':'run'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_error_df = pd.DataFrame.from_dict(step_error_dict,orient ='index',columns=['step_error'])\n",
    "step_error_df.reset_index(inplace=True)\n",
    "step_error_df.rename(columns={'index':'run'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(\n",
    "    df,\n",
    "    end_script_df,\n",
    "    how=\"inner\",\n",
    "    on=None,\n",
    "    left_on='run',\n",
    "    right_on='run',\n",
    "    left_index=False,\n",
    "    right_index=False,\n",
    "    sort=True,\n",
    "    suffixes=(\"_x\", \"_y\"),\n",
    "    copy=True,\n",
    "    indicator=False,\n",
    "    validate=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(\n",
    "    df,\n",
    "    step_error_df,\n",
    "    how=\"inner\",\n",
    "    on=None,\n",
    "    left_on='run',\n",
    "    right_on='run',\n",
    "    left_index=False,\n",
    "    right_index=False,\n",
    "    sort=True,\n",
    "    suffixes=(\"_x\", \"_y\"),\n",
    "    copy=True,\n",
    "    indicator=False,\n",
    "    validate=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'script_status': 'EA_script_status','step_state': 'EA_step_state','step_status': 'EA_step_status','step_error': 'IPT_step_error','script_completion': 'IPT_script_completion'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['KPI'] = 'Not mapped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K1\n",
    "mask = (df['scriptName'].str.contains('Place a sales local order',case=False))\n",
    "df['KPI'].mask(mask,'K01 Place a sales local order',inplace=True)\n",
    "\n",
    "# K2\n",
    "mask = (df['scriptName'].str.contains('Place a B2B local order',case=False))\n",
    "df['KPI'].mask(mask,'K02 Place a B2B/EDI order and Send Confirmation',inplace=True)\n",
    "\n",
    "# K3 Place Service Portal Order\n",
    "# No test script\n",
    "\n",
    "# K4\n",
    "mask = (df['scriptName'].str.contains('Amend an existing sales order',case=False))\n",
    "df['KPI'].mask(mask,'K04 Amend an existing sales order',inplace=True)\n",
    "\n",
    "# K5\n",
    "mask = (df['scriptName'].str.contains('Trade Returns Order',case=False))\n",
    "df['KPI'].mask(mask,'K05 Place a Trade Returns Order',inplace=True)\n",
    "\n",
    "# K6\n",
    "mask = (df['scriptName'].str.contains('Submit a B2B Remittance',case=False))\n",
    "df['KPI'].mask(mask,'K06 B2B Remittance',inplace=True)\n",
    "\n",
    "# K7 B2B Remittance Adjustment\n",
    "# No test script\n",
    "\n",
    "#K8\n",
    "mask = (df['scriptName'].str.contains('Receipted payment processing',case=False))\n",
    "df['KPI'].mask(mask,'K08 Receipted payment processing SA Only at the moment',inplace=True)\n",
    "\n",
    "# K9 aDSD Batch Job posting invoice for HHD billing document \n",
    "# No test script\n",
    "\n",
    "# K10\n",
    "mask = (df['scriptName'].str.contains('Credit status check',case=False))\n",
    "df['KPI'].mask(mask,'K10 Credit status check',inplace=True)\n",
    "\n",
    "# K11\n",
    "mask = (df['scriptName'].str.contains('Send Load to Roadnet',case=False))\n",
    "df['KPI'].mask(mask,'K11 Send Load to Roadnet load for Planning',inplace=True)\n",
    "\n",
    "# K12\n",
    "mask = (df['scriptName'].str.contains('Receive load from Roadnet',case=False))\n",
    "df['KPI'].mask(mask,'K12 Receive load from Roadnet into D365',inplace=True)\n",
    "\n",
    "# K13b\n",
    "mask = (df['scriptName'].str.contains('Release to warehouse',case=False) & df['scriptName'].str.contains('Roadnet loads',case=False))\n",
    "df['KPI'].mask(mask,'K13b Release to Warehouse & Complete Picking Work (Roadnet loads)',inplace=True)\n",
    "# Release to Warehouse (Roadnet loads) & Complete Picking Work & Process OOS\n",
    "\n",
    "# K13\n",
    "mask = (df['scriptName'].str.contains('Release to Warehouse',case=False) & df['scriptName'].str.contains('manual',case=False))\n",
    "df['KPI'].mask(mask,'K13 Release to Warehouse (manually planned loads)',inplace=True)\n",
    "\n",
    "# K14 Complete Picking Work & Process OOS \n",
    "# Not mapped??\n",
    "\n",
    "\n",
    "# K14b\n",
    "mask = (df['scriptName'].str.contains('Complete Picking Work',case=False) & df['scriptName'].str.contains('manual loads',case=False))\n",
    "df['KPI'].mask(mask,'K14b Complete Picking Work & Process OOS (manually planned loads)',inplace=True)\n",
    "\n",
    "# K15\n",
    "mask = (df['scriptName'].str.contains('aDSD Load confirmation',case=False))\n",
    "df['KPI'].mask(mask,'K15 aDSD Load confirmation',inplace=True)\n",
    "\n",
    "# K16\n",
    "mask = (df['scriptName'].str.contains('Load upload',case=False) & df['scriptName'].str.contains('Settlement',case=False))\n",
    "df['KPI'].mask(mask,'K16 Load upload & Settlement',inplace=True)\n",
    "\n",
    "# K17\n",
    "mask = (df['scriptName'].str.contains('Create a cost estimate',case=False))\n",
    "df['KPI'].mask(mask,'K17 Create a cost estimate for all standard costed procured materials',inplace=True)\n",
    "\n",
    "# K18\n",
    "mask = (df['scriptName'].str.contains('Imported Statistical',case=False))\n",
    "df['KPI'].mask(mask,'K18 Import Actual Statistical entries, into Cost Accounting',inplace=True)\n",
    "\n",
    "# K19\n",
    "mask = (df['scriptName'].str.contains('Distribute the range of items pending prices',case=False))\n",
    "df['KPI'].mask(mask,'K19 Distribute the range of items pending prices to another site',inplace=True)\n",
    "\n",
    "# K20\n",
    "mask = ((df['scriptName'].str.contains('Cost Rollup',case=False) & df['scriptName'].str.contains('Cost Allocation',case=False)) | df['scriptName'].str.contains('Maintain cost distribution table',case=False))\n",
    "df['KPI'].mask(mask,'K20 Run Cost Rollup and Cost Allocation Policies',inplace=True)\n",
    "\n",
    "# K21\n",
    "mask = (df['scriptName'].str.contains('Place SFA order',case=False))\n",
    "df['KPI'].mask(mask,'K21 Place SFA order and Send Confirmation',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['KPI', 'scriptId', 'scriptName', 'sessionId', 'run', 'lineNum'], inplace=True)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns={'topProjectName'}, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reindex(columns=['KPI', 'scriptId', 'scriptName', 'sessionId', 'run', 'EA_script_status', 'IPT_script_completion', 'IPT_step_error', 'lineNum', 'StepLabel', 'EA_step_state', 'EA_step_status', 'startTime', 'endTime', 'duration', 'duration_sec', 'duration_mins', 'date', 'time_dec','lastIssues'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the dataset for output on a specific test cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_scripts = ['TEST TIMINGS','Test - 10 sessions', 'Gary Test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = df.query(\"((date == '2023-02-02' and time_dec > 13.0) or (date == '2023-02-02' and time_dec > 0.0)) and scriptName not in @exclude_scripts\").copy()  # Remember time is UTC\n",
    "#df1 = df.query(\"date == '2023-02-05' and scriptName not in @exclude_scripts\").copy()  # Remember time is UTC\n",
    "rundate = '2023-02-27'\n",
    "df1 = df.query(\"date == @rundate and scriptName not in @exclude_scripts\").copy()  # Remember time is UTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New code to keep lastIssues only for those lineNums with a corresponding number - generated by ChatGPT :-)\n",
    "\n",
    "# df1['lastIssues'].fillna(value='', inplace=True)\n",
    "# mask = df1.apply(lambda x: '[ERROR] Step {}.'.format(str(int(x['lineNum']))) in x['lastIssues'], axis=1)\n",
    "# df1.loc[~mask, 'lastIssues'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" for i in tqdm(range(len(df1))):\\n    ln = str(df1.loc[i, 'lineNum'])\\n    lastIssue_str = str(df1.loc[i, 'lastIssues'])\\n    string1 = '[ERROR] Step '+ln+'.'\\n    check = (string1 in lastIssue_str)\\n    if check != True:\\n        df1.loc[i, 'lastIssues'] = '' \""
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Old code to keep lastIssues only for those lineNums with a corresponding number\n",
    "\n",
    "\"\"\" for i in tqdm(range(len(df1))):\n",
    "    ln = str(df1.loc[i, 'lineNum'])\n",
    "    lastIssue_str = str(df1.loc[i, 'lastIssues'])\n",
    "    string1 = '[ERROR] Step '+ln+'.'\n",
    "    check = (string1 in lastIssue_str)\n",
    "    if check != True:\n",
    "        df1.loc[i, 'lastIssues'] = '' \"\"\"\n",
    "\n",
    "# Previous runtime = 30.4s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "successful_runs = df1[df1['IPT_script_completion'] == 'Script completed'].groupby('KPI').agg({'run': 'nunique'}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "incomplete_runs = df1[df1['IPT_script_completion'] != 'Script completed'].groupby('KPI').agg({'run': 'nunique'}).reset_index()\n",
    "incomplete_runs.rename(columns={'run': 'Incomplete Runs', 'KPI': 'KPI Process'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mark those Test Script Steps that must be included in the time measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "testStepstoMeasure = {'K11 Send Load to Roadnet load for Planning': ['K11', 22], \n",
    "                        'K12 Receive load from Roadnet into D365': ['K12', 32],\n",
    "                        'K13b Release to Warehouse & Complete Picking Work (Roadnet loads)': ['K13b', 18, 'K14b', 62],    \n",
    "                        'K15 aDSD Load confirmation': ['K15', 16],\n",
    "                        'K16 Load upload & Settlement': ['K16', 0],\n",
    "                        'K20 Run Cost Rollup and Cost Allocation Policies': ['K20', 16],\n",
    "                        'K19 Distribute the range of items pending prices to another site': ['K19', 0],\n",
    "                        'K18 Import Actual Statistical entries, into Cost Accounting': ['K18', 39],\n",
    "                        'K17 Create a cost estimate for all standard costed procured materials': ['K17', 31]\n",
    "}\n",
    "\n",
    "# 'K13 Release to Warehouse (manually planned loads)': ['K13', 21, 'K14', 22],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['KPI_no'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Include_in_measure'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for idx in df1.index:\n",
    "    i = i + 1\n",
    "    #if i == 1000: break\n",
    "    scriptid = df1['scriptId'][idx]    \n",
    "    kpi_process = df1['KPI'][idx]   \n",
    "    try:\n",
    "        linenum = df1['lineNum'][idx]\n",
    "        if linenum in testStepstoMeasure[kpi_process]:\n",
    "            df1.at[idx,'Include_in_measure'] = True\n",
    "            j = [index for index, listItem in enumerate(testStepstoMeasure[kpi_process]) if listItem == linenum]       \n",
    "            df1.at[idx, 'KPI_no'] = testStepstoMeasure[kpi_process][j[0]-1]\n",
    "    except:\n",
    "        pass\n",
    "    # Exception below    \n",
    "    # if scriptid == 399 and linenum == 17 and df1['StepLabel'][idx] == 'Click OK':\n",
    "    if kpi_process == 'K13 Release to Warehouse (manually planned loads)':\n",
    "        label = df1['StepLabel'][idx]\n",
    "        if linenum == 21 and df1['StepLabel'][idx] == 'Click OK':\n",
    "            df1.at[idx, 'KPI_no'] = 'K13'\n",
    "            df1.at[idx,'Include_in_measure'] = True\n",
    "        if linenum == 22 and df1['StepLabel'][idx] == 'Click Complete work':\n",
    "            df1.at[idx, 'KPI_no'] = 'K14'\n",
    "            df1.at[idx,'Include_in_measure'] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" i = 0\n",
    "for idx in df1.index:\n",
    "    i = i + 1   \n",
    "    kpi_process = df1['KPI'][idx]\n",
    "    label = df1['StepLabel'][idx]\n",
    "    if linenum in testStepstoMeasure[kpi_process]:\n",
    "        df1.at[idx,'Include_in_measure'] = True         \n",
    "        df1.at[idx, 'KPI_no'] = testStepstoMeasure[kpi_process][j[0]-1 \"\"\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/execution/' + rundate +  '_results_filtered.csv'\n",
    "df1.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.query(\"Include_in_measure == True and EA_step_status != 'WARNING' and EA_step_status != 'ERROR'\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop_duplicates(keep='first')\n",
    "df2 = df2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 90th Percentile\n",
    "def q90(x):\n",
    "    return x.quantile(0.9)\n",
    "\n",
    "kpi_results = df2.groupby(['KPI_no']).agg({'KPI': 'first', 'duration_sec': ['mean', 'max', q90, 'std'], 'run': 'count'}).reset_index()\n",
    "\n",
    "# Flatten multi-level columns\n",
    "kpi_results.columns = ['_'.join(col) for col in kpi_results.columns]\n",
    "kpi_results = kpi_results.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpi_results.rename(columns={'KPI_no_': 'KPI_no', 'KPI_first':'KPI Process', 'duration_sec_mean': 'mean', 'duration_sec_max': 'max', 'duration_sec_q90': '90th_percentile', 'duration_sec_std': 'standard_dev', 'run_count': 'Successful Runs'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpi_results = pd.merge(\n",
    "    kpi_results,\n",
    "    incomplete_runs,\n",
    "    how=\"left\",\n",
    "    on=None,\n",
    "    left_on='KPI Process',\n",
    "    right_on='KPI Process',\n",
    "    left_index=False,\n",
    "    right_index=False,\n",
    "    sort=True,\n",
    "    suffixes=(\"_x\", \"_y\"),\n",
    "    copy=True,\n",
    "    indicator=False,\n",
    "    validate=None,\n",
    ")\n",
    "\n",
    "kpi_results['Incomplete Runs'] = kpi_results['Incomplete Runs'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KPI_no</th>\n",
       "      <th>KPI Process</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>90th_percentile</th>\n",
       "      <th>standard_dev</th>\n",
       "      <th>Successful Runs</th>\n",
       "      <th>Incomplete Runs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K11</td>\n",
       "      <td>K11 Send Load to Roadnet load for Planning</td>\n",
       "      <td>607.816667</td>\n",
       "      <td>612.387</td>\n",
       "      <td>612.0903</td>\n",
       "      <td>4.618403</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K12</td>\n",
       "      <td>K12 Receive load from Roadnet into D365</td>\n",
       "      <td>208.648800</td>\n",
       "      <td>312.694</td>\n",
       "      <td>283.3904</td>\n",
       "      <td>73.985141</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K13b</td>\n",
       "      <td>K13b Release to Warehouse &amp; Complete Picking W...</td>\n",
       "      <td>9.249151</td>\n",
       "      <td>40.569</td>\n",
       "      <td>13.3368</td>\n",
       "      <td>3.382975</td>\n",
       "      <td>205</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K14b</td>\n",
       "      <td>K13b Release to Warehouse &amp; Complete Picking W...</td>\n",
       "      <td>10.589027</td>\n",
       "      <td>93.114</td>\n",
       "      <td>21.0625</td>\n",
       "      <td>10.060444</td>\n",
       "      <td>328</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K15</td>\n",
       "      <td>K15 aDSD Load confirmation</td>\n",
       "      <td>53.026631</td>\n",
       "      <td>72.562</td>\n",
       "      <td>61.0999</td>\n",
       "      <td>5.858729</td>\n",
       "      <td>130</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  KPI_no                                        KPI Process        mean  \\\n",
       "0    K11         K11 Send Load to Roadnet load for Planning  607.816667   \n",
       "1    K12            K12 Receive load from Roadnet into D365  208.648800   \n",
       "2   K13b  K13b Release to Warehouse & Complete Picking W...    9.249151   \n",
       "3   K14b  K13b Release to Warehouse & Complete Picking W...   10.589027   \n",
       "4    K15                         K15 aDSD Load confirmation   53.026631   \n",
       "\n",
       "       max  90th_percentile  standard_dev  Successful Runs  Incomplete Runs  \n",
       "0  612.387         612.0903      4.618403               42              0.0  \n",
       "1  312.694         283.3904     73.985141                5              0.0  \n",
       "2   40.569          13.3368      3.382975              205              2.0  \n",
       "3   93.114          21.0625     10.060444              328              2.0  \n",
       "4   72.562          61.0999      5.858729              130              0.0  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kpi_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/execution/' + rundate +  '_kpi_results.xlsx'\n",
    "kpi_results.to_excel(filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "Stop right here!",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Stop right here!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wikus/code/CCBA_IPT/ccba_env/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3468: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "raise SystemExit(\"Stop right here!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental from here on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate to extract measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" def summary(x):\n",
    "    runs = x['executionLogsId'].nunique()\n",
    "    runs = float(runs)\n",
    "    duration = x['duration'].sum()/1000\n",
    "    duration_90 = x['duration'].quantile(0.9).sum()/1000\n",
    "    mean_s = x['duration'].mean()/1000\n",
    "    mean_90 = x['duration'].quantile(0.9).mean()/1000\n",
    "    count = duration/mean_s\n",
    "    result = {\n",
    "        #'aggr_duration': duration,\n",
    "        #'aggr_duration_minutes': duration/60,\n",
    "        #'runs': runs,\n",
    "        'mean': mean_s,\n",
    "        'mean_90': mean_90,\n",
    "        'mean_minutes': duration/runs/60\n",
    "        #'steps': count\n",
    "    }\n",
    "    return pd.Series(result).round(1)\n",
    "\n",
    "#df2.groupby(['scriptName','sessionId']).apply(summary).to_html('data/execution/result.html')\n",
    "df2.groupby(['testName', 'executionLogsId']).apply(summary).to_html('data/execution/result.html')\n",
    "#df2.groupby(['testName', 'executionLogsId']).quantile(.90).apply(summary).to_html('data/execution/result.html')\n",
    "#df2.groupby(['testName', 'executionLogsId']).apply(summary).to_excel('data/execution/result_groupby.xlsx')\n",
    "#df2.groupby(['testName', 'executionLogsId']).agg({'executionLogsId': {'nunique'}, 'duration' : {'sum'}})\n",
    "#df2.groupby(['testName']).apply(summary).to_html('data/execution/result.html') \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From here on the script is disabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert this to prevent the cells below from trying to write to the sql table\n",
    "raise SystemExit(\"Stop right here!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get ready to export to SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df['date'] > '2023-01-10')\n",
    "#df.loc[(df['date'] > '2023-01-10')]\n",
    "df = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://learn.microsoft.com/en-us/sql/machine-learning/data-exploration/python-dataframe-pandas?view=sql-server-ver16\n",
    "# Some other example server values are\n",
    "# server = 'localhost\\sqlexpress' # for a named instance\n",
    "# server = 'myserver,port' # to specify an alternate port\n",
    "server = 'tcp:csazniptlsql01.database.windows.net,1433' \n",
    "database = 'CSAZN-INT-IPT-L-DSQ-01' \n",
    "username = 'ccbaadmin' \n",
    "password = '@FireBase123' \n",
    "# ENCRYPT defaults to yes starting in ODBC Driver 18. It's good to always specify ENCRYPT=yes on the client side to avoid MITM attacks.\n",
    "cnxn = pyodbc.connect('DRIVER={ODBC Driver 18 for SQL Server};SERVER='+server+';DATABASE='+database+';ENCRYPT=yes;UID='+username+';PWD='+ password)\n",
    "cursor = cnxn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cursor = cnxn.cursor()\n",
    "\n",
    "# cursor.execute('''\n",
    "# \t\tCREATE TABLE ea_script_history (\n",
    "# \t\t\trecords_no int,\n",
    "#             topProjectName nvarchar(255),\n",
    "#             testName nvarchar(255),\n",
    "#             sessionId nvarchar(255),\n",
    "#             id int,\n",
    "#             scriptId int,\n",
    "#             scriptName nvarchar(255),\n",
    "#             state nvarchar(255),\n",
    "#             status nvarchar(255),\n",
    "#             StepLabel nvarchar(255),\n",
    "#             startTime datetime,\n",
    "#             endTime datetime,\n",
    "#             duration int,\n",
    "#             lineNum int,\n",
    "#             StepLogs_id int\n",
    "# \t\t\t)\n",
    "#                ''')\n",
    "\n",
    "# cnxn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnxn = pyodbc.connect('DRIVER={ODBC Driver 18 for SQL Server};SERVER='+server+';DATABASE='+database+';ENCRYPT=yes;UID='+username+';PWD='+ password)\n",
    "# cursor = cnxn.cursor()\n",
    "# # Insert Dataframe into SQL Server:\n",
    "# i = 0\n",
    "# for index, row in df.iterrows():\n",
    "#      cursor.execute(\"INSERT INTO ea_script_history (records_no,topProjectName,testName,sessionId,id,scriptId,scriptName,state,status,StepLabel,startTime,endTime,duration,lineNum,StepLogs_id) values(?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)\", row.records_no, row.topProjectName, row.testName, row.sessionId, row.id, row.scriptId, row.scriptName, row.state, row.status, row.StepLabel, row.startTime, row.endTime, row.duration, row.lineNum, row.StepLogs_id)\n",
    "#      i = i + 1\n",
    "#      if i == 1000:\n",
    "#           i = 0\n",
    "#           cnxn.commit()          \n",
    "# cnxn.commit()\n",
    "# cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnxn = pyodbc.connect('DRIVER={ODBC Driver 18 for SQL Server};SERVER='+server+';DATABASE='+database+';ENCRYPT=yes;UID='+username+';PWD='+ password)\n",
    "# cursor = cnxn.cursor()\n",
    "# # Insert Dataframe into SQL Server:\n",
    "# for index, row in df.iterrows():\n",
    "#      cursor.execute(\"INSERT INTO ea_script_history (startTime) values(?)\", row.startTime)\n",
    "# cnxn.commit()\n",
    "# cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all the rows in the SQl script history table\n",
    "# cursor = cnxn.cursor()\n",
    "# cursor.execute(\"DELETE FROM ea_script_history\")\n",
    "# cnxn.commit()\n",
    "# cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # Drop the SQl script history table (it must be re-created)\n",
    "cursor = cnxn.cursor()\n",
    "cursor.execute(\"DROP Table ea_script_history\")\n",
    "#cursor.execute(\"DROP Table temp_table\")\n",
    "cnxn.commit()\n",
    "cursor.close() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_steplabel = 'K14b Click Complete work'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_kpi = 'K14 '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if try_kpi in try_steplabel:\n",
    "    print('Match')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('ccba_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fc9d036103d1096928448d0b56931a711e4cbb0de213415ebc4bb6621893aebd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
